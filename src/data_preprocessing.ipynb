{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将不同数据集的数据统一转化为gml格式，用于输入今vasn，fm3等模型当中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T11:52:48.271927Z",
     "start_time": "2022-04-29T11:52:48.044053Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import networkx as nx\n",
    "from networkx.utils import is_string_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T11:52:48.281420Z",
     "start_time": "2022-04-29T11:52:48.273369Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_gml(G):\n",
    "    # gml图生成器直接将networkx源代码进行修改\n",
    "    # recursively make dicts into gml brackets\n",
    "    def listify(d,indent,indentlevel):\n",
    "        result='[ \\n'\n",
    "        for k,v in d.items():\n",
    "            if type(v)==dict:\n",
    "                v=listify(v,indent,indentlevel+1)\n",
    "            result += (indentlevel+1)*indent +                 string_item(k,v,indentlevel*indent)+'\\n'\n",
    "        return result+indentlevel*indent+\"]\"\n",
    "\n",
    "    def string_item(k,v,indent):\n",
    "        # try to make a string of the data\n",
    "        if type(v)==dict: \n",
    "            v=listify(v,indent,2)\n",
    "        elif is_string_like(v):\n",
    "            v='\"%s\"'%v\n",
    "        elif type(v)==bool:\n",
    "            v=int(v)\n",
    "        return \"%s %s\"%(k,v)\n",
    "\n",
    "    # check for attributes or assign empty dict\n",
    "    if hasattr(G,'graph_attr'):\n",
    "        graph_attr=G.graph_attr\n",
    "    else:\n",
    "        graph_attr={}\n",
    "    if hasattr(G,'node_attr'):\n",
    "        node_attr=G.node_attr\n",
    "    else:\n",
    "        node_attr={}\n",
    "\n",
    "    indent=2*' '\n",
    "    count=iter(range(len(G)))\n",
    "    node_id={}\n",
    "\n",
    "    yield \"graph [\"\n",
    "    if G.is_directed():\n",
    "        yield indent+\"directed 1\"\n",
    "    # write graph attributes \n",
    "    for k,v in G.graph.items():\n",
    "        if k == 'directed':\n",
    "            continue\n",
    "        yield indent+string_item(k,v,indent)\n",
    "    # write nodes\n",
    "    for n in G:\n",
    "        yield indent+\"node [\"\n",
    "        # get id or assign number\n",
    "        #nid=G.node[n].get('id',next(count))\n",
    "        #node_id[n]=nid\n",
    "        nid = n\n",
    "        node_id[n]=n\n",
    "        # 上两行对原代码进行修改，以原始输入的id作为输出图文件的id\n",
    "        yield 2*indent+\"id %s\"%nid\n",
    "        label=G.node[n].get('L', str(nid))\n",
    "#         node_json = G.node[n]['JSON']\n",
    "        if is_string_like(label):\n",
    "            label='\"%s\"'%label\n",
    "        yield 2*indent+'label %s'%label\n",
    "#         yield 2*indent+'json %s'%node_json\n",
    "        if n in G:\n",
    "          for k,v in G.node[n].items():\n",
    "              if k=='id' or k == 'label' or k == 'L' or k == 'JSON': continue\n",
    "              yield 2*indent+string_item(k,v,indent)\n",
    "        yield indent+\"]\"\n",
    "    # write edges\n",
    "    for u,v,edgedata in G.edges(data=True):\n",
    "#         source_color = G.node[u]['graphics']['fill']\n",
    "#         target_color = G.node[v]['graphics']['fill']\n",
    "        yield indent+\"edge [\"\n",
    "        yield 2*indent+\"source %s\"%u\n",
    "        yield 2*indent+\"target %s\"%v\n",
    "#         yield 2*indent+\"value 1.0\"\n",
    "#         # yield 2*indent+\"color \"+ get_edge_color_by_mixe_node_color(source_color, target_color)\n",
    "#         yield 2*indent+\"color #000000\"\n",
    "#         yield 2*indent+\"path \"+edge2path[str(u)+'|'+str(v)]\n",
    "        yield indent+\"]\"\n",
    "    yield \"]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T11:52:48.368492Z",
     "start_time": "2022-04-29T11:52:48.364299Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing_Slashdot0811():\n",
    "    # 用networkx将txt文件转换为gml文件\n",
    "    G = nx.Graph()\n",
    "    i = 0\n",
    "    edge_set = set()\n",
    "    with open('../datasets/Slashdot0811.txt', 'r') as fp:\n",
    "        datalines = fp.readlines()\n",
    "        for line in datalines:\n",
    "            i += 1\n",
    "            from_node, to_node = line.replace('\\n', '').split('\\t')\n",
    "            if from_node == to_node:\n",
    "                # 去掉自环\n",
    "                continue\n",
    "            if f'{from_node}\\t{to_node}' not in edge_set and f'{to_node}\\t{from_node}' not in edge_set:\n",
    "                # 去除双向连边中的一个，即0->1和1->0中的一个\n",
    "                edge_set.add(line)\n",
    "    for edge in edge_set:\n",
    "        from_node, to_node = edge.split('\\t')\n",
    "        G.add_edge(int(from_node), int(to_node))\n",
    "    if not os.path.exists('../temp/Slashdot0811/preprocessed_gml'): os.makedirs('../temp/Slashdot0811/preprocessed_gml')\n",
    "    with open('../temp/Slashdot0811/preprocessed_gml/graph.gml', 'w') as fp:\n",
    "        for line in generate_gml(G):\n",
    "            line+='\\n'\n",
    "            fp.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T11:52:50.250475Z",
     "start_time": "2022-04-29T11:52:50.233754Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing_Nature():\n",
    "    # 将csv文件转换为gml文件\n",
    "    G = nx.Graph()\n",
    "    with open('../datasets/Nature/Nature_out_id_title.csv') as fp:\n",
    "        csv_reader = csv.reader(fp)\n",
    "        for row in tqdm(csv_reader):\n",
    "            G.add_node(str(int(row[0], 16)))\n",
    "    with open('../datasets/Nature/Edges_Nature_out.csv') as fp:\n",
    "        csv_reader = csv.reader(fp)\n",
    "        for row in tqdm(csv_reader):\n",
    "            G.add_edge(str(int(row[0])), str(int(row[1])))\n",
    "    if not os.path.exists('../temp/Nature/preprocessed_gml'): os.makedirs('../temp/Nature/preprocessed_gml')\n",
    "    with open('../temp/Nature/preprocessed_gml/graph.gml', 'w') as fp:\n",
    "        for line in generate_gml(G):\n",
    "            line+='\\n'\n",
    "            fp.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T11:52:53.327167Z",
     "start_time": "2022-04-29T11:52:53.308690Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing_lasftm_asia():\n",
    "    G = nx.Graph()\n",
    "    i = 0\n",
    "    edge_set = set()\n",
    "    with open('../datasets/lasftm_asia/lastfm_asia_edges.csv', 'r') as fp:\n",
    "        csv_reader = csv.reader(fp)\n",
    "        header = next(csv_reader)\n",
    "        for line in csv_reader:\n",
    "            i += 1\n",
    "            from_node, to_node = line[0], line[1]\n",
    "            if from_node == to_node:\n",
    "                # 去掉自环\n",
    "                continue\n",
    "            if f'{from_node}|{to_node}' not in edge_set and f'{to_node}|{from_node}' not in edge_set:\n",
    "                # 去除双向连边中的一个，即0->1和1->0中的一个\n",
    "                edge_set.add(f'{from_node}|{to_node}')\n",
    "    for edge in edge_set:\n",
    "        from_node, to_node = edge.split('|')\n",
    "        G.add_edge(int(from_node), int(to_node))\n",
    "    if not os.path.exists('../temp/lasftm_asia/preprocessed_gml'): os.makedirs('../temp/lasftm_asia/preprocessed_gml')\n",
    "    with open('../temp/lasftm_asia/preprocessed_gml/graph.gml', 'w') as fp:\n",
    "        for line in generate_gml(G):\n",
    "            line+='\\n'\n",
    "            fp.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T11:52:53.988258Z",
     "start_time": "2022-04-29T11:52:53.968955Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing_facebook_large():\n",
    "    G = nx.Graph()\n",
    "    i = 0\n",
    "    edge_set = set()\n",
    "    with open('../datasets/facebook_large/musae_facebook_edges.csv', 'r') as fp:\n",
    "        csv_reader = csv.reader(fp)\n",
    "        header = next(csv_reader)\n",
    "        for line in csv_reader:\n",
    "            i += 1\n",
    "            from_node, to_node = line[0], line[1]\n",
    "            if from_node == to_node:\n",
    "                # 去掉自环\n",
    "                continue\n",
    "            if f'{from_node}|{to_node}' not in edge_set and f'{to_node}|{from_node}' not in edge_set:\n",
    "                # 去除双向连边中的一个，即0->1和1->0中的一个\n",
    "                edge_set.add(f'{from_node}|{to_node}')\n",
    "    for edge in edge_set:\n",
    "        from_node, to_node = edge.split('|')\n",
    "        G.add_edge(int(from_node), int(to_node))\n",
    "    if not os.path.exists('../temp/facebook_large/preprocessed_gml'): os.makedirs('../temp/facebook_large/preprocessed_gml')\n",
    "    with open('../temp/facebook_large/preprocessed_gml/graph.gml', 'w') as fp:\n",
    "        for line in generate_gml(G):\n",
    "            line+='\\n'\n",
    "            fp.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T11:52:54.427648Z",
     "start_time": "2022-04-29T11:52:54.411645Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing_com_amazon():\n",
    "    # 用networkx将txt文件转换为gml文件\n",
    "    G = nx.Graph()\n",
    "    i = 0\n",
    "    edge_set = set()\n",
    "    with open('../datasets/com-amazon.txt', 'r') as fp:\n",
    "        datalines = fp.readlines()\n",
    "        for line in datalines:\n",
    "            i += 1\n",
    "            from_node, to_node = line.replace('\\n', '').split('\\t')\n",
    "            if from_node == to_node:\n",
    "                # 去掉自环\n",
    "                continue\n",
    "            if f'{from_node}\\t{to_node}' not in edge_set and f'{to_node}\\t{from_node}' not in edge_set:\n",
    "                # 去除双向连边中的一个，即0->1和1->0中的一个\n",
    "                edge_set.add(line)\n",
    "    for edge in edge_set:\n",
    "        from_node, to_node = edge.split('\\t')\n",
    "        G.add_edge(int(from_node), int(to_node))\n",
    "    if not os.path.exists('../temp/com_amazon/preprocessed_gml'): os.makedirs('../temp/com_amazon/preprocessed_gml')\n",
    "    with open('../temp/com_amazon/preprocessed_gml/graph.gml', 'w') as fp:\n",
    "        for line in generate_gml(G):\n",
    "            line+='\\n'\n",
    "            fp.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T11:52:54.931549Z",
     "start_time": "2022-04-29T11:52:54.911066Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing_DBLP():\n",
    "    # 将DBLP数据存储在preprocessed_gml的graph.gml文件中，并存储am_paper_id所对应的dblp会议或期刊分类\n",
    "    id_set = set() # 用于去除数据多对一的情况\n",
    "    pid2cluster = {}\n",
    "    with open('../datasets/DBLP/dblp2am_paper_id2id.csv', 'r') as csvfile:\n",
    "        csv_reader = csv.reader(csvfile)\n",
    "        header = next(csv_reader)\n",
    "        for row in tqdm(csv_reader):\n",
    "            conf_or_journal = row[0].split('/')[0]\n",
    "            conf_or_journal_name = row[0].split('/')[1]\n",
    "            if conf_or_journal == 'conf' or conf_or_journal == 'journals':\n",
    "                if row[1] not in id_set:\n",
    "                    id_set.add(str(row[1]))\n",
    "                    pid2cluster[str(row[1])] = f'{conf_or_journal}/{conf_or_journal_name}'\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "    G = nx.Graph()\n",
    "    for p_id in tqdm(id_set):\n",
    "        G.add_node(p_id)\n",
    "        \n",
    "    with open('../datasets/DBLP/dblp_edges.csv', 'r') as csvfile:\n",
    "        csv_reader = csv.reader(csvfile)\n",
    "        header = next(csv_reader)\n",
    "        for row in tqdm(csv_reader):\n",
    "            if str(row[0]) in id_set and str(row[1]) in id_set:\n",
    "                G.add_edge(str(row[0]), str(row[1]))\n",
    "    \n",
    "    if not os.path.exists('../temp/DBLP/preprocessed_gml'): os.makedirs('../temp/DBLP/preprocessed_gml')\n",
    "    with open('../temp/DBLP/preprocessed_gml/graph.gml', 'w') as fp:\n",
    "        for line in generate_gml(G):\n",
    "            line+='\\n'\n",
    "            fp.write(line)\n",
    "    json.dump(pid2cluster, open('../temp/DBLP/preprocessed_gml/pid2cluster.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T10:20:37.559636Z",
     "start_time": "2022-04-26T10:20:30.827527Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    preprocessing_com_amazon()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vasn]",
   "language": "python",
   "name": "vasn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
