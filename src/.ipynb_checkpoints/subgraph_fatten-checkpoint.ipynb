{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据布局好的子图以及子图间的结构拼合成为一张大图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T13:14:26.185596Z",
     "start_time": "2022-04-25T13:14:25.992767Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import config\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from readgml import readgml\n",
    "from networkx.utils import is_string_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T13:14:26.687797Z",
     "start_time": "2022-04-25T13:14:26.680128Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_subgraph_r(path):\n",
    "    # 获取子图内部连边的度（通过连边统计），以及布局之后的图半径，通过gml文件统计\n",
    "    # 跟精细的处理是对图进行中心化，即通过图的上下左右节点的坐标，求出水平和竖直方向和坐标原点的位移，然后做平移即得到中心化的图\n",
    "    nodes, edges = readgml.read_gml(path)\n",
    "    r_max = 0\n",
    "    for node in nodes:\n",
    "        x = node['x']\n",
    "        y = node['y']\n",
    "        r = math.sqrt(x**2 + y**2)\n",
    "        if r > r_max:\n",
    "            r_max = r\n",
    "    return r_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T13:14:27.000008Z",
     "start_time": "2022-04-25T13:14:26.978497Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_gml(G):\n",
    "    # gml图生成器直接将networkx源代码进行修改\n",
    "    # recursively make dicts into gml brackets\n",
    "    def listify(d,indent,indentlevel):\n",
    "        result='[ \\n'\n",
    "        for k,v in d.items():\n",
    "            if type(v)==dict:\n",
    "                v=listify(v,indent,indentlevel+1)\n",
    "            result += (indentlevel+1)*indent + \\\n",
    "                string_item(k,v,indentlevel*indent)+'\\n'\n",
    "        return result+indentlevel*indent+\"]\"\n",
    "\n",
    "    def string_item(k,v,indent):\n",
    "        # try to make a string of the data\n",
    "        if type(v)==dict: \n",
    "            v=listify(v,indent,2)\n",
    "        elif is_string_like(v):\n",
    "            v='\"%s\"'%v\n",
    "        elif type(v)==bool:\n",
    "            v=int(v)\n",
    "        return \"%s %s\"%(k,v)\n",
    "\n",
    "    # check for attributes or assign empty dict\n",
    "    if hasattr(G,'graph_attr'):\n",
    "        graph_attr=G.graph_attr\n",
    "    else:\n",
    "        graph_attr={}\n",
    "    if hasattr(G,'node_attr'):\n",
    "        node_attr=G.node_attr\n",
    "    else:\n",
    "        node_attr={}\n",
    "\n",
    "    indent=2*' '\n",
    "    count=iter(range(len(G)))\n",
    "    node_id={}\n",
    "\n",
    "    yield \"graph [\"\n",
    "    if G.is_directed():\n",
    "        yield indent+\"directed 1\"\n",
    "    # write graph attributes \n",
    "    for k,v in G.graph.items():\n",
    "        if k == 'directed':\n",
    "            continue\n",
    "        yield indent+string_item(k,v,indent)\n",
    "    # write nodes\n",
    "    for n in G:\n",
    "        yield indent+\"node [\"\n",
    "        # get id or assign number\n",
    "        #nid=G.node[n].get('id',next(count))\n",
    "        #node_id[n]=nid\n",
    "        nid = n\n",
    "        node_id[n]=n\n",
    "        # 上两行对原代码进行修改，以原始输入的id作为输出图文件的id\n",
    "        yield 2*indent+\"id %s\"%nid\n",
    "        label=G.node[n]['L']\n",
    "        if is_string_like(label):\n",
    "            label='\"%s\"'%label\n",
    "        yield 2*indent+'label %s'%label\n",
    "        if n in G:\n",
    "          for k,v in G.node[n].items():\n",
    "              if k=='id' or k == 'label' or k == 'L': continue\n",
    "              yield 2*indent+string_item(k,v,indent)\n",
    "        yield indent+\"]\"\n",
    "    # write edges\n",
    "    for u,v,edgedata in G.edges(data=True):\n",
    "        source_color = G.node[u]['graphics']['fill']\n",
    "        target_color = G.node[v]['graphics']['fill']\n",
    "        yield indent+\"edge [\"\n",
    "        yield 2*indent+\"source %s\"%u\n",
    "        yield 2*indent+\"target %s\"%v\n",
    "        yield indent+\"]\"\n",
    "    yield \"]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T13:14:27.379332Z",
     "start_time": "2022-04-25T13:14:27.347783Z"
    }
   },
   "outputs": [],
   "source": [
    "def subgraph_fatten():\n",
    "    # 获取每个子图等效节点的实际半径，圆心坐标\n",
    "    # 在前一步骤已经丢弃了部分非联通分量\n",
    "    # 若不在set里的整数id则不是子图的等效节点, 这些节点是为了等效社区添加的辅助节点，ID从最大子图ID下一个开始\n",
    "    subgraph_list_set = set([file.split('.')[0] for file in os.listdir(f'../temp/{config.DATASET}/subgraphs')])  \n",
    "    \n",
    "    nodes, edges = readgml.read_gml(f'../temp/{config.DATASET}/equivalence_structure_layouted/equivalence_structure.gml')\n",
    "    \n",
    "    T1 = time.perf_counter()\n",
    "    subgraph2position, subgraph2r = {}, {}\n",
    "    for node in nodes:\n",
    "        if str(node['id']) in subgraph_list_set:\n",
    "            x = node['x']\n",
    "            y = node['y']\n",
    "            subgraph2position[str(node['id'])] = [x, y]\n",
    "            subgraph2r[str(node['id'])] = node['w']\n",
    "    \n",
    "    # 获取还原结构的比例，子图布局与节点大小不变，变换等效结构，如果不变换等效结构，缩放子图坐标，而不缩放节点大小，会使得节点发生重叠\n",
    "    subgraph2acc_r = {}\n",
    "    r_ratio = []\n",
    "    for subgraph in subgraph2r:\n",
    "        subgraph2acc_r[subgraph] = get_subgraph_r(f'../temp/{config.DATASET}/layouted_subgraphs/{subgraph}.gml')\n",
    "        r_ratio.append(float(subgraph2acc_r[subgraph])/float(subgraph2r[subgraph]))\n",
    "    stretch_factor = np.mean(r_ratio)\n",
    "    # 根据等效结构拼合子图\n",
    "    color_list = [\n",
    "        '#ff6666',\n",
    "        '#0099cc',\n",
    "        '#ffff66',\n",
    "        '#ff9900',\n",
    "        '#99cc33',\n",
    "        '#cc6699',\n",
    "        '#9933ff',\n",
    "        '#33cc33',\n",
    "        '#9966cc',\n",
    "        '#ff33cc',\n",
    "        '#009966'\n",
    "    ]\n",
    "    # 此段代码用于实际的应用当中，但由于此次代码的目的是为了跑实验，故先注释掉，节约跑代码的时间\n",
    "    #==========================#\n",
    "#     i = 0\n",
    "#     G = nx.Graph()\n",
    "#     for subgraph in subgraph2r:\n",
    "#         nodes, edges = readgml.read_gml(f'../temp/{config.DATASET}/layouted_subgraphs/{subgraph}.gml')\n",
    "#         for node in nodes:\n",
    "#             node_id = str(node['id'])\n",
    "#             whd = node['w']\n",
    "#             color = color_list[i%11]\n",
    "#             x = node['x'] + subgraph2position[str(subgraph)][0] * stretch_factor\n",
    "#             y = node['y'] + subgraph2position[str(subgraph)][1] * stretch_factor\n",
    "#             G.add_node(node_id, graphics = {'x':x,'y':y,'z':0,'w':whd,'h':whd,'d':whd,'fill':color}, L = '')\n",
    "#         for edge in edges:\n",
    "#             G.add_edge(str(edge['source']),str(edge['target']))\n",
    "#         i += 1\n",
    "    \n",
    "#     if not os.path.exists(f'../temp/{config.DATASET}/fattened_large_graph_without_subgraph_edge'): # 保存子图之间不存在连边的拼合好的大图\n",
    "#         os.makedirs(f'../temp/{config.DATASET}/fattened_large_graph_without_subgraph_edge')\n",
    "#     # 这个gml用于直接出图，类似生成dblp那一类的大图，时间关系就不继续开发了，后续如果有需要就接着这个写，包括一些节点大小，节点颜色的设置\n",
    "#     # 由于后续评估不需要，因此相关节点属性设置不再继续开发\n",
    "#     # 输出两个大图文件，第一个是不包含子图之间连边的大图用于直接可视化，第二个是包含子图之间连边的大图用于后续和其他算法比较计算时间\n",
    "#     with open(f'../temp/{config.DATASET}/fattened_large_graph_without_subgraph_edge/fattened_large_graph.gml', 'w') as fp:\n",
    "#         for line in generate_gml(G):\n",
    "#             line+='\\n'\n",
    "#             fp.write(line)\n",
    "    #==========================#\n",
    "    # 包含子图之间连边的大图用于后续和其他算法比较计算时间\n",
    "    i = 0\n",
    "    final_layout_json = {}  # VSAN以及Tulip的最终layout均用json存储与评估，且VSAN不再进行后期的微调操作\n",
    "    final_layout_json['node_position'] = {} #用于存储最后节点的位置即二维空间的坐标\n",
    "    final_layout_json['edges'] = [] # 用于存储图的连边，从而在后续的评估中计算图论距离\n",
    "    node_set = set()\n",
    "    G2Tulip = nx.Graph()\n",
    "    for subgraph in subgraph2r:\n",
    "        nodes, edges = readgml.read_gml(f'../temp/{config.DATASET}/layouted_subgraphs/{subgraph}.gml')\n",
    "        for node in nodes:\n",
    "            node_id = str(node['id'])\n",
    "            G2Tulip.add_node(str(node_id))\n",
    "            node_set.add(node_id)\n",
    "            whd = node['w']\n",
    "            color = color_list[i%11]\n",
    "            # 这一块与上面直接出图对大图进行拼接不同，上面对等效结构的缩放会使得图结构超出gephi的方形区域，而此处使用对子图缩放，将图范围限制在可控范围内\n",
    "            x = node['x']/stretch_factor + subgraph2position[str(subgraph)][0]\n",
    "            y = node['y']/stretch_factor + subgraph2position[str(subgraph)][1]\n",
    "            final_layout_json['node_position'][str(node_id)] = [x, y]\n",
    "        i += 1\n",
    "    T2 = time.perf_counter()\n",
    "    delta_t = (T2 - T1)*1000\n",
    "    executed_time = json.load(open(f'../temp/{config.DATASET}/executed_time.json', 'r'))\n",
    "    executed_time['subgraph_fatten'] = delta_t\n",
    "    json.dump(executed_time, open(f'../temp/{config.DATASET}/executed_time.json', 'w'))\n",
    "    \n",
    "    G_original = nx.read_gml(f'../temp/{config.DATASET}/preprocessed_gml/graph.gml')\n",
    "    for source, target in G_original.edges:\n",
    "        if str(source) in node_set and str(target) in node_set:\n",
    "            final_layout_json['edges'].append([str(source),str(target)])\n",
    "            G2Tulip.add_edge(str(source),str(target))\n",
    "    \n",
    "    if not os.path.exists(f'../temp/{config.DATASET}/final_layout_json_to_evaluation'): # 保存子图之间存在连边的拼合好的大图\n",
    "        os.makedirs(f'../temp/{config.DATASET}/final_layout_json_to_evaluation')\n",
    "    json.dump(final_layout_json, open(f'../temp/{config.DATASET}/final_layout_json_to_evaluation/vasn.json', 'w'))\n",
    "    if not os.path.exists(f'../temp/{config.DATASET}/gml_to_tulip_layout'): # 保存子图之间存在连边的拼合好的大图\n",
    "        os.makedirs(f'../temp/{config.DATASET}/gml_to_tulip_layout')\n",
    "    nx.write_gml(G_original, f'../temp/{config.DATASET}/gml_to_tulip_layout/graph.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T13:14:29.261687Z",
     "start_time": "2022-04-25T13:14:28.608709Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    subgraph_fatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vasn]",
   "language": "python",
   "name": "vasn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
