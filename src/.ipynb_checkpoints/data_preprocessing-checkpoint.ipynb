{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将不同数据集的数据统一转化为gml格式，用于输入今vasn，fm3等模型当中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:03:37.785916Z",
     "start_time": "2022-04-26T03:03:37.746091Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import networkx as nx\n",
    "from networkx.utils import is_string_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T12:59:38.408859Z",
     "start_time": "2022-04-25T12:59:38.381253Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_gml(G):\n",
    "    # gml图生成器直接将networkx源代码进行修改\n",
    "    # recursively make dicts into gml brackets\n",
    "    def listify(d,indent,indentlevel):\n",
    "        result='[ \\n'\n",
    "        for k,v in d.items():\n",
    "            if type(v)==dict:\n",
    "                v=listify(v,indent,indentlevel+1)\n",
    "            result += (indentlevel+1)*indent +                 string_item(k,v,indentlevel*indent)+'\\n'\n",
    "        return result+indentlevel*indent+\"]\"\n",
    "\n",
    "    def string_item(k,v,indent):\n",
    "        # try to make a string of the data\n",
    "        if type(v)==dict: \n",
    "            v=listify(v,indent,2)\n",
    "        elif is_string_like(v):\n",
    "            v='\"%s\"'%v\n",
    "        elif type(v)==bool:\n",
    "            v=int(v)\n",
    "        return \"%s %s\"%(k,v)\n",
    "\n",
    "    # check for attributes or assign empty dict\n",
    "    if hasattr(G,'graph_attr'):\n",
    "        graph_attr=G.graph_attr\n",
    "    else:\n",
    "        graph_attr={}\n",
    "    if hasattr(G,'node_attr'):\n",
    "        node_attr=G.node_attr\n",
    "    else:\n",
    "        node_attr={}\n",
    "\n",
    "    indent=2*' '\n",
    "    count=iter(range(len(G)))\n",
    "    node_id={}\n",
    "\n",
    "    yield \"graph [\"\n",
    "    if G.is_directed():\n",
    "        yield indent+\"directed 1\"\n",
    "    # write graph attributes \n",
    "    for k,v in G.graph.items():\n",
    "        if k == 'directed':\n",
    "            continue\n",
    "        yield indent+string_item(k,v,indent)\n",
    "    # write nodes\n",
    "    for n in G:\n",
    "        yield indent+\"node [\"\n",
    "        # get id or assign number\n",
    "        #nid=G.node[n].get('id',next(count))\n",
    "        #node_id[n]=nid\n",
    "        nid = n\n",
    "        node_id[n]=n\n",
    "        # 上两行对原代码进行修改，以原始输入的id作为输出图文件的id\n",
    "        yield 2*indent+\"id %s\"%nid\n",
    "        label=G.node[n].get('L', str(nid))\n",
    "#         node_json = G.node[n]['JSON']\n",
    "        if is_string_like(label):\n",
    "            label='\"%s\"'%label\n",
    "        yield 2*indent+'label %s'%label\n",
    "#         yield 2*indent+'json %s'%node_json\n",
    "        if n in G:\n",
    "          for k,v in G.node[n].items():\n",
    "              if k=='id' or k == 'label' or k == 'L' or k == 'JSON': continue\n",
    "              yield 2*indent+string_item(k,v,indent)\n",
    "        yield indent+\"]\"\n",
    "    # write edges\n",
    "    for u,v,edgedata in G.edges(data=True):\n",
    "#         source_color = G.node[u]['graphics']['fill']\n",
    "#         target_color = G.node[v]['graphics']['fill']\n",
    "        yield indent+\"edge [\"\n",
    "        yield 2*indent+\"source %s\"%u\n",
    "        yield 2*indent+\"target %s\"%v\n",
    "#         yield 2*indent+\"value 1.0\"\n",
    "#         # yield 2*indent+\"color \"+ get_edge_color_by_mixe_node_color(source_color, target_color)\n",
    "#         yield 2*indent+\"color #000000\"\n",
    "#         yield 2*indent+\"path \"+edge2path[str(u)+'|'+str(v)]\n",
    "        yield indent+\"]\"\n",
    "    yield \"]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T12:59:39.106189Z",
     "start_time": "2022-04-25T12:59:39.091094Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing_Slashdot0811():\n",
    "    # 用networkx将txt文件转换为gml文件\n",
    "    G = nx.Graph()\n",
    "    i = 0\n",
    "    edge_set = set()\n",
    "    with open('../datasets/Slashdot0811.txt', 'r') as fp:\n",
    "        datalines = fp.readlines()\n",
    "        for line in datalines:\n",
    "            i += 1\n",
    "            from_node, to_node = line.replace('\\n', '').split('\\t')\n",
    "            if from_node == to_node:\n",
    "                # 去掉自环\n",
    "                continue\n",
    "            if f'{from_node}\\t{to_node}' not in edge_set and f'{to_node}\\t{from_node}' not in edge_set:\n",
    "                # 去除双向连边中的一个，即0->1和1->0中的一个\n",
    "                edge_set.add(line)\n",
    "    for edge in edge_set:\n",
    "        from_node, to_node = edge.split('\\t')\n",
    "        G.add_edge(int(from_node), int(to_node))\n",
    "    if not os.path.exists('../temp/Slashdot0811/preprocessed_gml'): os.makedirs('../temp/Slashdot0811/preprocessed_gml')\n",
    "    with open('../temp/Slashdot0811/preprocessed_gml/graph.gml', 'w') as fp:\n",
    "        for line in generate_gml(G):\n",
    "            line+='\\n'\n",
    "            fp.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T12:59:40.867550Z",
     "start_time": "2022-04-25T12:59:40.843494Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing_email_Eu_core():\n",
    "    G = nx.Graph()\n",
    "    i = 0\n",
    "    edge_set = set()\n",
    "    with open('../datasets/email-Eu-core.txt', 'r') as fp:\n",
    "        datalines = fp.readlines()\n",
    "        for line in datalines:\n",
    "            i += 1\n",
    "            from_node, to_node = line.replace('\\n', '').split(' ')\n",
    "            if from_node == to_node:\n",
    "                # 去掉自环\n",
    "                continue\n",
    "            if f'{from_node} {to_node}' not in edge_set and f'{to_node} {from_node}' not in edge_set:\n",
    "                # 去除双向连边中的一个，即0->1和1->0中的一个\n",
    "                edge_set.add(line)\n",
    "    for edge in edge_set:\n",
    "        from_node, to_node = edge.split(' ')\n",
    "        G.add_edge(int(from_node), int(to_node))\n",
    "    if not os.path.exists('../temp/email_Eu_core/preprocessed_gml'): os.makedirs('../temp/email_Eu_core/preprocessed_gml')\n",
    "    with open('../temp/email_Eu_core/preprocessed_gml/graph.gml', 'w') as fp:\n",
    "        for line in generate_gml(G):\n",
    "            line+='\\n'\n",
    "            fp.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T12:43:29.693380Z",
     "start_time": "2022-04-25T12:43:29.689256Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing_Nature():\n",
    "    G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:09:03.318684Z",
     "start_time": "2022-04-26T03:09:03.291314Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing_lasftm_asia():\n",
    "    G = nx.Graph()\n",
    "    i = 0\n",
    "    edge_set = set()\n",
    "    with open('../datasets/lasftm_asia/lastfm_asia_edges.csv', 'r') as fp:\n",
    "        csv_reader = csv.reader(fp)\n",
    "        header = next(csv_reader)\n",
    "        for line in csv_reader:\n",
    "            i += 1\n",
    "            from_node, to_node = line[0], line[1]\n",
    "            if from_node == to_node:\n",
    "                # 去掉自环\n",
    "                continue\n",
    "            if f'{from_node}|{to_node}' not in edge_set and f'{to_node}|{from_node}' not in edge_set:\n",
    "                # 去除双向连边中的一个，即0->1和1->0中的一个\n",
    "                edge_set.add(f'{from_node}|{to_node}')\n",
    "    for edge in edge_set:\n",
    "        from_node, to_node = edge.split('|')\n",
    "        G.add_edge(int(from_node), int(to_node))\n",
    "    if not os.path.exists('../temp/lasftm_asia/preprocessed_gml'): os.makedirs('../temp/lasftm_asia/preprocessed_gml')\n",
    "    with open('../temp/lasftm_asia/preprocessed_gml/graph.gml', 'w') as fp:\n",
    "        for line in generate_gml(G):\n",
    "            line+='\\n'\n",
    "            fp.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_git_web_ml():\n",
    "    G = nx.Graph()\n",
    "    i = 0\n",
    "    edge_set = set()\n",
    "    with open('../datasets/git_web_ml/musae_git_edges.csv', 'r') as fp:\n",
    "        csv_reader = csv.reader(fp)\n",
    "        header = next(csv_reader)\n",
    "        for line in csv_reader:\n",
    "            i += 1\n",
    "            from_node, to_node = line[0], line[1]\n",
    "            if from_node == to_node:\n",
    "                # 去掉自环\n",
    "                continue\n",
    "            if f'{from_node}|{to_node}' not in edge_set and f'{to_node}|{from_node}' not in edge_set:\n",
    "                # 去除双向连边中的一个，即0->1和1->0中的一个\n",
    "                edge_set.add(f'{from_node}|{to_node}')\n",
    "    for edge in edge_set:\n",
    "        from_node, to_node = edge.split('|')\n",
    "        G.add_edge(int(from_node), int(to_node))\n",
    "    if not os.path.exists('../temp/git_web_ml/preprocessed_gml'): os.makedirs('../temp/git_web_ml/preprocessed_gml')\n",
    "    with open('../temp/git_web_ml/preprocessed_gml/graph.gml', 'w') as fp:\n",
    "        for line in generate_gml(G):\n",
    "            line+='\\n'\n",
    "            fp.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:09:14.834007Z",
     "start_time": "2022-04-26T03:09:14.670714Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    preprocessing_lasftm_asia()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vasn]",
   "language": "python",
   "name": "vasn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
